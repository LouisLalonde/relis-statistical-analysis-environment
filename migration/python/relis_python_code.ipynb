{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Python R code analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>Parsing and beautifing data</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and load the necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew, shapiro, spearmanr, pearsonr \n",
    "from statsmodels.robust.scale import mad\n",
    "from FisherExact import fisher_exact\n",
    "from matplotlib import ticker\n",
    "from relis_types.FieldClassificationType import FieldClassificationType\n",
    "from relis_types.Multivalue import Multivalue\n",
    "from relis_types.Policies import Policies\n",
    "from relis_types.Variable import Variable\n",
    "from relis_types.DataFrame import DataFrame\n",
    "from relis_types.NominalVariables import NominalVariables\n",
    "from relis_types.NominalDataFrame import NominalDataFrame\n",
    "from relis_types.ContinuousVariables import ContinuousVariables\n",
    "from relis_types.ContinuousDataFrame import ContinuousDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we create an utils class/file ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeEmptyStrings(df: pd.DataFrame) -> None:\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "\n",
    "def get_variable(field_name: str, variables) -> Variable:\n",
    "    return variables[field_name].value\n",
    "\n",
    "def split_multiple_values(value):\n",
    "    if not pd.isna(value):\n",
    "        return [item.strip() for item in re.split(rf'\\{Multivalue.SEPARATOR.value}', value)] \n",
    "    return [value]\n",
    "\n",
    "def process_multiple_values(values: pd.Series, multiple: bool):\n",
    "    if (multiple):\n",
    "        return values.apply(lambda x: split_multiple_values(x))\n",
    "\n",
    "    return values.apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project data objects will not be in JSON files. They will be accessible directly from the relis application environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../data/relis_classification_rsc_CV.json', 'r', encoding='utf8') as f:\n",
    "   classification_data: list[dict[str, str]] =  json.loads(f.read())\n",
    "\n",
    "print(classification_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split config file based on data type\n",
    "def filter_row_by_field_type(paper, field_type):\n",
    "    pd_row = {key: value[\"value\"] for key, value in paper.items() if value['type'] == field_type}\n",
    "    return pd_row\n",
    "\n",
    "nominal_data = pd.DataFrame([filter_row_by_field_type(paper, FieldClassificationType.NOMINAL.value) for paper in classification_data])\n",
    "continuous_data = pd.DataFrame([filter_row_by_field_type(paper, FieldClassificationType.CONTINUOUS.value) for paper in classification_data])\n",
    "\n",
    "nominal = NominalDataFrame(nominal_data, NominalVariables)\n",
    "continuous = ContinuousDataFrame(continuous_data, ContinuousVariables)\n",
    "\n",
    "# For test purpose ?\n",
    "if (Policies.DROPNA.value):\n",
    "    removeEmptyStrings(nominal.data)\n",
    "    removeEmptyStrings(continuous.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>DESCRIPTIVE STATS</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_data_desc(field_name: str, data: pd.DataFrame):\n",
    "    # Get metadata\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "\n",
    "    # Split the values by the \"|\" character and flatten the result\n",
    "    split_values = process_multiple_values(data[field_name], variable.multiple)\n",
    "    flattened_values = np.concatenate(split_values)\n",
    "\n",
    "    # Generate the frequency table\n",
    "    freq_table = pd.Series(flattened_values, dtype=str).value_counts().reset_index()\n",
    "    freq_table.columns = ['value', 'n']\n",
    "\n",
    "    # Calculate the percentage\n",
    "    freq_table['percentage'] = (freq_table['n'] / freq_table['n'].sum()) * 100\n",
    "\n",
    "    return freq_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Frequency tables<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we do with the empty values ? Do they need to be part of the statistics calculation. <br>\n",
    "Currently, I'll proceed by deleting them in the begining of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_distr_vector = {NominalVariables[field_name]: beautify_data_desc(field_name, nominal.data)\n",
    "                      for field_name in nominal.data.columns}\n",
    "\n",
    "print(desc_distr_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we do with the empty values ? Do they need to be part of the statistics calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Bar Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bar_plot(field_name: str, data: pd.DataFrame):\n",
    "    df = beautify_data_desc(field_name, data)\n",
    "    \n",
    "    if (len(df) == 0):\n",
    "        return\n",
    "\n",
    "    # Set the theme\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    barplot = sns.barplot(data=df, x=\"value\", y=\"percentage\", hue=\"n\")\n",
    "\n",
    "    # Get metadata\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "\n",
    "    # Set labels and title\n",
    "    title = f\"{variable.title} ~ Bar plot\"\n",
    "    barplot.set_title(title)\n",
    "    barplot.set_xlabel(variable.title)\n",
    "    barplot.set_ylabel(\"Percentage\")\n",
    "\n",
    "    return barplot.figure\n",
    "\n",
    "bar_plot_vector = {NominalVariables[field_name]: generate_bar_plot(field_name, nominal.data)\n",
    "                    for field_name in nominal.data.columns}\n",
    "\n",
    "print(desc_distr_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Statistics\n",
    "<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_statistics(field_name: str, data: pd.DataFrame):\n",
    "    series =  data[field_name]\n",
    "    \n",
    "    series.replace('', np.nan, inplace=True)\n",
    "    \n",
    "    if (len(data) == 0):\n",
    "        return\n",
    "\n",
    "    nan_policy = 'omit' if Policies.DROPNA.value else 'propagate'\n",
    "    results = {\n",
    "    \"vars\": 1,\n",
    "    \"n\": series.count(),\n",
    "    \"mean\": series.mean(),\n",
    "    \"sd\": series.std(),\n",
    "    \"median\": series.median(),\n",
    "    \"trimmed\": series[series.between(series.quantile(0.25), series.quantile(0.75))].mean(),\n",
    "    \"mad\": mad(series),\n",
    "    \"min\": series.min(),\n",
    "    \"max\": series.max(),\n",
    "    \"range\": series.max() - series.min(),\n",
    "    \"skew\": skew(series, nan_policy=nan_policy),\n",
    "    \"kurtosis\": kurtosis(series, nan_policy=nan_policy, fisher=True),\n",
    "    \"se\": series.std() / np.sqrt(series.count())  \n",
    "    }\n",
    "    return results\n",
    "\n",
    "statistics_vector = {ContinuousVariables[field_name]: generate_statistics(field_name, continuous.data)\n",
    "                      for field_name in continuous.data.columns}\n",
    "print(statistics_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Box Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_box_plot(field_name: str, data: pd.DataFrame):\n",
    "    series = data[field_name]\n",
    "\n",
    "    variable = get_variable(field_name, ContinuousVariables)\n",
    "\n",
    "    # Create the box plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=series, color='lightblue')\n",
    "\n",
    "    # Overlay the mean point\n",
    "    mean_value = series.mean()\n",
    "    plt.scatter(x=0, y=mean_value, color='red', s=50, zorder=3)  # s is the size of the point\n",
    "\n",
    "    # Set the title and labels\n",
    "    title = f\"{variable.title} ~ Box plot\"\n",
    "    plt.title(title)\n",
    "    plt.ylabel(variable.title)\n",
    "    plt.xlabel('')\n",
    "\n",
    "    plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.0f'))\n",
    "    plt.close()\n",
    "    return plt\n",
    "\n",
    "box_plot_vector = {ContinuousVariables[field_name]: generate_box_plot(field_name, continuous.data)\n",
    "                    for field_name in continuous.data.columns}\n",
    "\n",
    "box_plot_vector[ContinuousVariables.publication_year].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Violin Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_violin_plot(field_name: str, data: pd.DataFrame):\n",
    "    series = data[field_name]\n",
    "    \n",
    "    variable = get_variable(field_name, ContinuousVariables)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(data=series, color=\"lightgray\")\n",
    "\n",
    "    plt.title(f\"{variable.title} ~ Violin plot\")\n",
    "    plt.ylabel(variable.title)\n",
    "    plt.xlabel(\"Density\")\n",
    "    plt.xticks([])\n",
    "\n",
    "    return plt\n",
    "\n",
    "violin_plot_vector = {ContinuousVariables[field_name]: generate_violin_plot(field_name, continuous.data)\n",
    "                       for field_name in continuous.data.columns}\n",
    "print(violin_plot_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>EVOLUTIVE STATS</u></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is Publication.year a classfication field which is mandatory for each of the project ? <br>\n",
    "It's currently hard coded and doesn't follow any patern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_data_evo(field_name: str, publication_year: pd.Series, variable: Variable, data: pd.DataFrame):\n",
    "    series = data[field_name]\n",
    "    \n",
    "    # Create new DataFrame with specified columns\n",
    "    subset_data = pd.DataFrame({\n",
    "        'Year': publication_year,\n",
    "        'Value': process_multiple_values(series, variable.multiple)\n",
    "    })\n",
    "    \n",
    "    subset_data = subset_data.explode('Value')\n",
    "\n",
    "    # Remove rows with empty values\n",
    "    subset_data = subset_data[(subset_data['Value'] != '')]\n",
    "\n",
    "    subset_data = subset_data.groupby(['Year', 'Value']).size().reset_index(name='Frequency')\n",
    "\n",
    "    return subset_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:pink\">Frequency tables<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_data(field_name: str, publication_year: pd.Series, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_evo(field_name, publication_year, variable, data)\n",
    "\n",
    "    # Pivoting the data\n",
    "    subset_data = subset_data.pivot(index='Year', columns='Value', values='Frequency').fillna(0)\n",
    "\n",
    "    subset_data.columns.name = None\n",
    "    subset_data.reset_index(inplace=True)\n",
    "\n",
    "    return subset_data \n",
    "\n",
    "\n",
    "evo_distr_vector = {NominalVariables[field_name]: expand_data(field_name, continuous.data[\"publication_year\"], nominal.data)\n",
    "                       for field_name in nominal.data.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:pink\">Evolution Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evo_plot(field_name: str, publication_year: pd.Series, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    \n",
    "    subset_data = beautify_data_evo(field_name, publication_year, variable, data)\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=subset_data, x='Year', y='Frequency', hue='Value', style='Value', markers=True)\n",
    "\n",
    "    # Setting title, labels, and theme\n",
    "    plt.title(f\"{variable.title} ~ Evolution plot\")\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    return plt\n",
    "\n",
    "evolution_plot_vector = {NominalVariables[field_name]: generate_evo_plot(field_name, continuous.data[\"publication_year\"], nominal.data)\n",
    "                          for field_name in nominal.data.columns}\n",
    "print(evolution_plot_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>COMPARATIVE STATS</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_data_comp(field_name: str, dependency_field_name: str,\n",
    "                        variable: Variable, dependency_variable: Variable, data: pd.DataFrame):    \n",
    "    subset_data = pd.DataFrame({\n",
    "        field_name: data[field_name],\n",
    "        dependency_field_name: data[dependency_field_name]\n",
    "    })\n",
    "    \n",
    "    # Filtering out rows where any of the variables is empty\n",
    "    subset_data = subset_data[(subset_data[field_name] != \"\") & (subset_data[dependency_field_name] != \"\")]\n",
    "\n",
    "    # Splitting the strings and expanding into separate rows\n",
    "    subset_data[field_name] = process_multiple_values(subset_data[field_name], variable.multiple)\n",
    "    subset_data = subset_data.explode(field_name)\n",
    "\n",
    "    subset_data[dependency_field_name] = process_multiple_values(subset_data[dependency_field_name],\n",
    "                                                                  dependency_variable.multiple)\n",
    "    subset_data = subset_data.explode(dependency_field_name)\n",
    "\n",
    "    # Counting occurrences\n",
    "    subset_data = subset_data.groupby([field_name, dependency_field_name]).size().reset_index(name='Frequency')\n",
    "\n",
    "    return subset_data\n",
    "\n",
    "def evaluate_comparative_dependency_field(field_name: str, dataFrame: DataFrame, strategy):\n",
    "    \"\"\"\n",
    "    Perform a statistical analysis strategy for each \n",
    "    dependency field of a given classification field.\n",
    "    Act as a wrapper for the comparative statistical\n",
    "    functions\n",
    "    \"\"\"\n",
    "    field_names = list(dataFrame.data.columns)\n",
    "\n",
    "    return {dataFrame.variable_type[dependency_field_name]: strategy(field_name, dependency_field_name, dataFrame.data)\n",
    "             for dependency_field_name in field_names if dependency_field_name != field_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Frequency Tables<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparative_violin_plot(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    return beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "violin_plot_vector = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, generate_comparative_violin_plot)\n",
    "                       for field_name in nominal.data.columns}\n",
    "\n",
    "print(violin_plot_vector[NominalVariables.industrial][NominalVariables.domain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Bar Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stacked_bar_plot(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    # Pivot the data to get a matrix form\n",
    "    pivoted_data = subset_data.pivot(index=field_name, columns=dependency_field_name, values='Frequency')\n",
    "\n",
    "    # Replace NaN values with 0\n",
    "    pivoted_data = pivoted_data.fillna(0)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Bottom value for stacking\n",
    "    bottom_value = pd.Series([0] * pivoted_data.shape[0], index=pivoted_data.index)\n",
    "\n",
    "    for col in pivoted_data.columns:\n",
    "        plt.bar(pivoted_data.index, pivoted_data[col], bottom=bottom_value, label=col)\n",
    "        bottom_value += pivoted_data[col]\n",
    "\n",
    "    plt.title(f\"{variable.title} and {dependency_variable.title} ~ Stacked bar plot\")\n",
    "    plt.xlabel(variable.title)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(title=dependency_field_name)\n",
    "\n",
    "    return plt\n",
    "\n",
    "stacked_bar_plot_vector = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, generate_stacked_bar_plot)\n",
    "                       for field_name in nominal.data.columns}\n",
    "print(stacked_bar_plot_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Grouped Bar Plots<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only diverge from the stacked bar plot by the dodge attribute set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grouped_bar_plot(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=field_name, y='Frequency', hue=dependency_field_name, data=subset_data, dodge=True)\n",
    "\n",
    "    plt.title(f\"{variable.title} and {dependency_variable.title} ~ Grouped bar plot\")\n",
    "    plt.gca().set_xlabel('')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    return plt\n",
    "\n",
    "grouped_bar_plot_vector = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, generate_grouped_bar_plot)\n",
    "                       for field_name in nominal.data.columns}\n",
    "print(grouped_bar_plot_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Bubble Charts<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend in the original script has more steps for the values (step value of 0.5)<br>\n",
    "This type of figure will benefit from coloring the dots based on the frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bubble_chart(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    # Creating the bubble chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=subset_data, x=field_name, y=dependency_field_name, size='Frequency', color='black')\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.title(f\"{variable.title} and {dependency_variable.title} ~ Bubble Chart\")\n",
    "    plt.gca().set_xlabel('')\n",
    "    plt.gca().set_ylabel('')\n",
    "\n",
    "    return plt\n",
    "\n",
    "bubble_chart_vector = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, generate_bubble_chart)\n",
    "                       for field_name in nominal.data.columns}\n",
    "print(bubble_chart_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Fisher's Exact Test<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library used: https://github.com/maclandrol/FisherExact has an obsolete numpy dtype which causes the test to fail when the simulate_pval is set to True. An issue has been opened to let the devs know about the problem.\n",
    "\n",
    "simulate_pval is mandatory to make the R results reproducdive in the python env.\n",
    "\n",
    "To temporary fix the issue, the library should be pull from git and rebuild with the fix\n",
    "\n",
    "1) change np.float to np.float32 in the fact = np.zeros(wkslimit + 1, dtype=np.float, order='F') assignation \n",
    "2) python3 setup.py install to build the library locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_exact_test(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    # Check for the condition where there's only one row and both variables are NaN\n",
    "    if len(subset_data) == 1 and pd.isna(subset_data[field_name]).all() and pd.isna(subset_data[dependency_field_name]).all():\n",
    "        return\n",
    "\n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(subset_data[field_name], subset_data[dependency_field_name],\n",
    "                                     values=subset_data['Frequency'], aggfunc='sum', dropna=False).fillna(0)\n",
    "\n",
    "    # Perform Fisher's Exact Test\n",
    "    fisher_result = fisher_exact(contingency_table, simulate_pval=True)\n",
    "\n",
    "    # return fisher_result\n",
    "    return fisher_result\n",
    "\n",
    "fisher_exact_test_vector = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, fisher_exact_test)\n",
    "                       for field_name in nominal.data.columns}\n",
    "print(fisher_exact_test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Shapiro Wilk's Correlation Test<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shapiro Wilk's Correlation Test\n",
    "\n",
    "def shapiro_wilk_test(field_name: str, continuous_df: pd.DataFrame):\n",
    "    subset_data = continuous_df[field_name].fillna(0)\n",
    "\n",
    "    shapiro_result = shapiro(subset_data)\n",
    "\n",
    "    return shapiro_result\n",
    "\n",
    "shapiro_wilk_test_vector = {ContinuousVariables[field_name]: shapiro_wilk_test(field_name, continuous.data)\n",
    "                          for field_name in continuous.data.columns}\n",
    "print(shapiro_wilk_test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Pearson's Correlation Test<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_cor_test(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    _, pvalue = shapiro_wilk_test_vector[ContinuousVariables[field_name]]\n",
    "    _, dpvalue = shapiro_wilk_test_vector[ContinuousVariables[dependency_field_name]]\n",
    "\n",
    "    if not (pvalue > 0.05 and dpvalue > 0.05): return\n",
    "    \n",
    "    # Perform Pearson's correlation test\n",
    "    pearson_coefficient, p_value = pearsonr(data[field_name].fillna(0), data[dependency_field_name].fillna(0))\n",
    "\n",
    "    return pearson_coefficient, p_value\n",
    "\n",
    "pearson_cor_test_vector = {ContinuousVariables[field_name]: evaluate_comparative_dependency_field(field_name, continuous, pearson_cor_test)\n",
    "                       for field_name in continuous.data.columns}\n",
    "\n",
    "print(pearson_cor_test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Spearman's Correlation Test<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<ContinuousVariables.publication_year: <relis_types.Variable.Variable object at 0x7fa619bc9fc0>>: {<ContinuousVariables.targeted_year: <relis_types.Variable.Variable object at 0x7fa619bca050>>: SignificanceResult(statistic=0.12423546683420235, pvalue=0.7694442841303335)}, <ContinuousVariables.targeted_year: <relis_types.Variable.Variable object at 0x7fa619bca050>>: {<ContinuousVariables.publication_year: <relis_types.Variable.Variable object at 0x7fa619bc9fc0>>: SignificanceResult(statistic=0.12423546683420235, pvalue=0.7694442841303335)}}\n"
     ]
    }
   ],
   "source": [
    "def spearman_cor_test(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    _, pvalue = shapiro_wilk_test_vector[ContinuousVariables[field_name]]\n",
    "    _, dpvalue = shapiro_wilk_test_vector[ContinuousVariables[dependency_field_name]]\n",
    "\n",
    "    if  pvalue > 0.05 and dpvalue > 0.05: return\n",
    "  \n",
    "    # Perform Spearman's correlation test\n",
    "    spearman_result = spearmanr(data[field_name].fillna(0), data[dependency_field_name].fillna(0))\n",
    "\n",
    "    return spearman_result\n",
    "\n",
    "spearman_cor_test_vector = {ContinuousVariables[field_name]: evaluate_comparative_dependency_field(field_name, continuous, spearman_cor_test)\n",
    "                       for field_name in continuous.data.columns}\n",
    "\n",
    "print(spearman_cor_test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
