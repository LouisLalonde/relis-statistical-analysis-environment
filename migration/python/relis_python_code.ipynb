{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Python R code analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>Parsing and beautifing data</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and load the necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew, shapiro, spearmanr, pearsonr, chi2_contingency\n",
    "from statsmodels.robust.scale import mad\n",
    "from FisherExact import fisher_exact\n",
    "from matplotlib import ticker\n",
    "from relis_types.Multivalue import Multivalue\n",
    "from relis_types.Policies import Policies\n",
    "from relis_types.Variable import Variable\n",
    "from relis_types.DataFrame import DataFrame\n",
    "from relis_types.NominalVariables import NominalVariables\n",
    "from relis_types.NominalDataFrame import NominalDataFrame\n",
    "from relis_types.ContinuousVariables import ContinuousVariables\n",
    "from relis_types.ContinuousDataFrame import ContinuousDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = {\"axes.edgecolor\": \"black\", \"grid.linestyle\": \"dashed\", \"grid.color\": \"grey\"}\n",
    "sns.set_style(\"darkgrid\", rc = custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substituteNan(df: pd.DataFrame) -> None:\n",
    "    df.replace(np.nan, '', inplace=True)\n",
    "\n",
    "def get_variable(field_name: str, variables) -> Variable:\n",
    "    return variables[field_name].value\n",
    "\n",
    "def split_multiple_values(value):\n",
    "    if not pd.isna(value):\n",
    "        return [item.strip() for item in re.split(rf'\\{Multivalue.SEPARATOR.value}', value)] \n",
    "    return [value]\n",
    "\n",
    "def process_multiple_values(values: pd.Series, multiple: bool):\n",
    "    if (multiple):\n",
    "        return values.apply(lambda x: split_multiple_values(x))\n",
    "\n",
    "    return values.apply(lambda x: [x])\n",
    "\n",
    "def dataFrameGetTitle(statistic_type: str, statistic_name: str,\n",
    "                          field_name: str, dependency_field_name = None):\n",
    "    \n",
    "    base_str =  f\"{statistic_type} | {statistic_name} : {field_name}\"\n",
    "\n",
    "    if dependency_field_name: base_str += f\"->{dependency_field_name}\"\n",
    "\n",
    "    return {'title': base_str}\n",
    "\n",
    "def dataFrameUpdateTitle(dataFrame: pd.DataFrame, object: dict):\n",
    "    dataFrame.attrs.update(object)\n",
    "\n",
    "def display_data(dataFrame: pd.DataFrame | None, bool: bool):\n",
    "    if type(dataFrame) != pd.DataFrame:\n",
    "        print(\"No data... Nothing to show\")\n",
    "    elif bool:\n",
    "        if dataFrame.attrs.get('title'): print(dataFrame.attrs.get('title'))\n",
    "        print(dataFrame.to_markdown())\n",
    "        print(\"\\n\")\n",
    "\n",
    "def display_figure(plt, bool: bool):\n",
    "    if bool: plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_classification_data = pd.read_csv('../data/relis_classification_CV.csv', encoding='utf8')\n",
    "\n",
    "nominal_variables = {nominal_variable.value.title: nominal_variable.name for nominal_variable in NominalVariables}\n",
    "continious_variables = {continious_variable.value.title: continious_variable.name for continious_variable in ContinuousVariables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_data = project_classification_data[nominal_variables.keys()].rename(columns=nominal_variables)\n",
    "continuous_data = project_classification_data[continious_variables.keys()].rename(columns=continious_variables)\n",
    "\n",
    "if (not Policies.DROP_NA.value):\n",
    "    substituteNan(nominal_data)\n",
    "    substituteNan(continuous_data)\n",
    "\n",
    "nominal = NominalDataFrame(nominal_data, NominalVariables)\n",
    "continuous = ContinuousDataFrame(continuous_data, ContinuousVariables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>DESCRIPTIVE STATS</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_data_desc(field_name: str, data: pd.DataFrame):\n",
    "    # Get metadata\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "\n",
    "    # Split the values by the \"|\" character and flatten the result\n",
    "    split_values = process_multiple_values(data[field_name], variable.multiple)\n",
    "    flattened_values = np.concatenate(split_values)\n",
    "\n",
    "    # Generate the frequency table\n",
    "    freq_table = pd.Series(flattened_values, dtype=str).value_counts().reset_index()\n",
    "    freq_table.columns = ['value', 'n']\n",
    "\n",
    "    # Calculate the percentage\n",
    "    freq_table['percentage'] = (freq_table['n'] / freq_table['n'].sum()) * 100\n",
    "\n",
    "    return freq_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Frequency tables<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we do with the empty values ? Do they need to be part of the statistics calculation. <br>\n",
    "Currently, I'll proceed by deleting them in the begining of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc_frequency_table(field_name: str, data: pd.DataFrame):\n",
    "    return beautify_data_desc(field_name, data)\n",
    "\n",
    "desc_frequency_tables = {NominalVariables[field_name]: generate_desc_frequency_table(field_name, nominal.data)\n",
    "                      for field_name in nominal.data.columns}\n",
    "\n",
    "print(desc_frequency_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we do with the empty values ? Do they need to be part of the statistics calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Bar Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc_bar_plot(field_name: str, data: pd.DataFrame):\n",
    "    df = beautify_data_desc(field_name, data)\n",
    "\n",
    "    if (len(df) == 0): return\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    hue = \"n\"\n",
    "    sns.barplot(data=df, x=\"value\", y=\"percentage\", hue=hue, dodge=False)\n",
    "    # Get metadata\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "\n",
    "    # Set labels and title\n",
    "    title = f\"{variable.title} ~ Bar plot\"\n",
    "    plt.title(title)\n",
    "    plt.xlabel(variable.title)\n",
    "    plt.ylabel(\"Percentage\")\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title=hue)\n",
    "    plt.gca().get_legend().get_frame().set_edgecolor('black')\n",
    "\n",
    "    return fig\n",
    "\n",
    "desc_bar_plots = {NominalVariables[field_name]: generate_desc_bar_plot(field_name, nominal.data)\n",
    "                    for field_name in nominal.data.columns}\n",
    "\n",
    "print(desc_bar_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Statistics\n",
    "<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc_statistics(field_name: str, data: pd.DataFrame):\n",
    "    series =  data[field_name]\n",
    "\n",
    "    series.replace('', np.nan, inplace=True)\n",
    "\n",
    "    if (len(data) == 0): return\n",
    "\n",
    "    nan_policy = 'omit' if Policies.DROP_NA.value else 'propagate'\n",
    "    results = {\n",
    "    \"vars\": 1,\n",
    "    \"n\": series.count(),\n",
    "    \"mean\": series.mean(),\n",
    "    \"sd\": series.std(),\n",
    "    \"median\": series.median(),\n",
    "    \"trimmed\": series[series.between(series.quantile(0.25), series.quantile(0.75))].mean(),\n",
    "    \"mad\": mad(series),\n",
    "    \"min\": series.min(),\n",
    "    \"max\": series.max(),\n",
    "    \"range\": series.max() - series.min(),\n",
    "    \"skew\": skew(series, nan_policy=nan_policy),\n",
    "    \"kurtosis\": kurtosis(series, nan_policy=nan_policy, fisher=True),\n",
    "    \"se\": series.std() / np.sqrt(series.count())  \n",
    "    }\n",
    "    return results\n",
    "\n",
    "desc_statistics = {ContinuousVariables[field_name]: generate_desc_statistics(field_name, continuous.data)\n",
    "                      for field_name in continuous.data.columns}\n",
    "print(desc_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Box Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc_box_plot(field_name: str, data: pd.DataFrame):\n",
    "    series = data[field_name]\n",
    "\n",
    "    variable = get_variable(field_name, ContinuousVariables)\n",
    "\n",
    "    # Create the box plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.boxplot(data=series, color='lightblue', dodge=False)\n",
    "\n",
    "    # Overlay the mean point\n",
    "    mean_value = series.mean()\n",
    "    plt.scatter(x=0, y=mean_value, color='red', s=50, zorder=3)  # s is the size of the point\n",
    "\n",
    "    # Set the title and labels\n",
    "    title = f\"{variable.title} ~ Box plot\"\n",
    "    plt.title(title)\n",
    "    plt.ylabel(variable.title)\n",
    "    plt.xlabel('')\n",
    "\n",
    "    plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.0f'))\n",
    "\n",
    "    return fig\n",
    "\n",
    "desc_box_plots = {ContinuousVariables[field_name]: generate_desc_box_plot(field_name, continuous.data)\n",
    "                    for field_name in continuous.data.columns}\n",
    "\n",
    "desc_box_plots[ContinuousVariables.publication_year].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:orange\">Violin Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc_violin_plot(field_name: str, data: pd.DataFrame):\n",
    "    series = data[field_name]\n",
    "    \n",
    "    variable = get_variable(field_name, ContinuousVariables)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.violinplot(data=series, color=\"lightgray\", dodge=False)\n",
    "\n",
    "    plt.title(f\"{variable.title} ~ Violin plot\")\n",
    "    plt.ylabel(variable.title)\n",
    "    plt.xlabel(\"Density\")\n",
    "    plt.xticks([])\n",
    "\n",
    "    return fig\n",
    "\n",
    "desc_violin_plots = {ContinuousVariables[field_name]: generate_desc_violin_plot(field_name, continuous.data)\n",
    "                       for field_name in continuous.data.columns}\n",
    "print(desc_violin_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>EVOLUTIVE STATS</u></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is Publication.year a classfication field which is mandatory for each of the project ? <br>\n",
    "It's currently hard coded and doesn't follow any patern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_data_evo(field_name: str, publication_year: pd.Series, variable: Variable, data: pd.DataFrame):\n",
    "    series = data[field_name]\n",
    "    \n",
    "    # Create new DataFrame with specified columns\n",
    "    subset_data = pd.DataFrame({\n",
    "        'Year': publication_year,\n",
    "        'Value': process_multiple_values(series, variable.multiple)\n",
    "    })\n",
    "    \n",
    "    subset_data = subset_data.explode('Value')\n",
    "\n",
    "    # Remove rows with empty values\n",
    "    subset_data = subset_data[(subset_data['Value'] != '')]\n",
    "\n",
    "    subset_data = subset_data.groupby(['Year', 'Value']).size().reset_index(name='Frequency')\n",
    "\n",
    "    return subset_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:pink\">Frequency tables<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evo_frequency_table(field_name: str, publication_year: pd.Series, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_evo(field_name, publication_year, variable, data)\n",
    "\n",
    "    # Pivoting the data\n",
    "    subset_data = subset_data.pivot(index='Year', columns='Value', values='Frequency').fillna(0)\n",
    "\n",
    "    subset_data.columns.name = None\n",
    "    subset_data.reset_index(inplace=True)\n",
    "\n",
    "    return subset_data \n",
    "\n",
    "\n",
    "evo_frequency_tables = {NominalVariables[field_name]: generate_evo_frequency_table(field_name, continuous.data[\"publication_year\"], nominal.data)\n",
    "                       for field_name in nominal.data.columns}\n",
    "\n",
    "print(evo_frequency_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:pink\">Evolution Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evo_plot(field_name: str, publication_year: pd.Series, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    \n",
    "    subset_data = beautify_data_evo(field_name, publication_year, variable, data)\n",
    "\n",
    "    # Create a plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    hue = 'Value'\n",
    "    sns.lineplot(data=subset_data, x='Year', y='Frequency', hue=hue, style='Value', markers=True)\n",
    "\n",
    "    # Setting title, labels, and theme\n",
    "    plt.title(f\"{variable.title} ~ Evolution plot\")\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title=hue)\n",
    "\n",
    "    return fig\n",
    "\n",
    "evo_plots = {NominalVariables[field_name]: generate_evo_plot(field_name, continuous.data[\"publication_year\"], nominal.data)\n",
    "                          for field_name in nominal.data.columns}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>COMPARATIVE STATS</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_data_comp(field_name: str, dependency_field_name: str,\n",
    "                        variable: Variable, dependency_variable: Variable, data: pd.DataFrame):    \n",
    "    subset_data = pd.DataFrame({\n",
    "        field_name: data[field_name],\n",
    "        dependency_field_name: data[dependency_field_name]\n",
    "    })\n",
    "    \n",
    "    # Filtering out rows where any of the variables is empty\n",
    "    subset_data = subset_data[(subset_data[field_name] != \"\") & (subset_data[dependency_field_name] != \"\")]\n",
    "\n",
    "    # Splitting the strings and expanding into separate rows\n",
    "    subset_data[field_name] = process_multiple_values(subset_data[field_name], variable.multiple)\n",
    "    subset_data = subset_data.explode(field_name)\n",
    "\n",
    "    subset_data[dependency_field_name] = process_multiple_values(subset_data[dependency_field_name],\n",
    "                                                                  dependency_variable.multiple)\n",
    "    subset_data = subset_data.explode(dependency_field_name)\n",
    "\n",
    "    # Counting occurrences\n",
    "    subset_data = subset_data.groupby([field_name, dependency_field_name]).size().reset_index(name='Frequency')\n",
    "\n",
    "    return subset_data\n",
    "\n",
    "def evaluate_comparative_dependency_field(field_name: str, dataFrame: DataFrame, strategy):\n",
    "    \"\"\"\n",
    "    Perform a statistical analysis strategy for each \n",
    "    dependency field of a given classification field.\n",
    "    Act as a wrapper for the comparative statistical\n",
    "    functions\n",
    "    \"\"\"\n",
    "    field_names = list(dataFrame.data.columns)\n",
    "\n",
    "    return {dataFrame.variable_type[dependency_field_name]: strategy(field_name, dependency_field_name, dataFrame.data)\n",
    "             for dependency_field_name in field_names if dependency_field_name != field_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Frequency Tables<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comp_frequency_table(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    return beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "comp_frequency_tables = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, generate_comp_frequency_table)\n",
    "                       for field_name in nominal.data.columns}\n",
    "\n",
    "print(comp_frequency_tables[NominalVariables.industrial][NominalVariables.domain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Bar Plots<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comp_stacked_bar_plot(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    # Pivot the data to get a matrix form\n",
    "    pivoted_data = subset_data.pivot(index=field_name, columns=dependency_field_name, values='Frequency')\n",
    "\n",
    "    # Replace NaN values with 0\n",
    "    pivoted_data = pivoted_data.fillna(0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Bottom value for stacking\n",
    "    bottom_value = pd.Series([0] * pivoted_data.shape[0], index=pivoted_data.index)\n",
    "\n",
    "    for col in pivoted_data.columns:\n",
    "        plt.bar(pivoted_data.index, pivoted_data[col], bottom=bottom_value, label=col)\n",
    "        bottom_value += pivoted_data[col]\n",
    "\n",
    "    plt.title(f\"{variable.title} and {dependency_variable.title} ~ Stacked bar plot\")\n",
    "    plt.xlabel(variable.title)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title=dependency_field_name)\n",
    "\n",
    "    return fig\n",
    "\n",
    "comp_stacked_bar_plots = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, generate_comp_stacked_bar_plot)\n",
    "                       for field_name in nominal.data.columns}\n",
    "print(comp_stacked_bar_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Grouped Bar Plots<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only diverge from the stacked bar plot by the dodge attribute set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comp_grouped_bar_plot(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(x=field_name, y='Frequency', hue=dependency_field_name, data=subset_data, dodge=True)\n",
    "\n",
    "    plt.title(f\"{variable.title} and {dependency_variable.title} ~ Grouped bar plot\")\n",
    "    plt.gca().set_xlabel('')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title=dependency_field_name)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "comp_grouped_bar_plots = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, generate_comp_grouped_bar_plot)\n",
    "                       for field_name in nominal.data.columns}\n",
    "print(comp_grouped_bar_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Bubble Charts<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend in the original script has more steps for the values (step value of 0.5)<br>\n",
    "This type of figure will benefit from coloring the dots based on the frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comp_bubble_chart(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    # Creating the bubble chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    size = 'Frequency'\n",
    "    sns.scatterplot(data=subset_data, x=field_name, y=dependency_field_name, size=size, color='black')\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.title(f\"{variable.title} and {dependency_variable.title} ~ Bubble Chart\")\n",
    "    plt.gca().set_xlabel('')\n",
    "    plt.gca().set_ylabel('')\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title=size)\n",
    "\n",
    "    return fig\n",
    "\n",
    "comp_bubble_charts = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, generate_comp_bubble_chart)\n",
    "                       for field_name in nominal.data.columns}\n",
    "print(comp_bubble_charts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Fisher's Exact Test<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library used: https://github.com/maclandrol/FisherExact has an obsolete numpy dtype which causes the test to fail when the simulate_pval is set to True. An issue has been opened to let the devs know about the problem.\n",
    "\n",
    "simulate_pval is mandatory to make the R results reproducdive in the python env.\n",
    "\n",
    "To temporary fix the issue, the library should be pull from git and rebuild with the fix\n",
    "\n",
    "1) change np.float to np.float32 in the fact = np.zeros(wkslimit + 1, dtype=np.float, order='F') assignation \n",
    "2) python3 setup.py install to build the library locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NominalVariables.venue\n",
      "                        fisher-exact-test chi2-exact-test\n",
      "search_type                          None            None\n",
      "domain                               None            None\n",
      "transformation_language              None            None\n",
      "source_language                      None            None\n",
      "target_language                      None            None\n",
      "scope                                None            None\n",
      "industrial                           None            None\n",
      "bidirectional                        None            None\n",
      "NominalVariables.search_type\n",
      "                        fisher-exact-test chi2-exact-test\n",
      "venue                                None            None\n",
      "domain                               None            None\n",
      "transformation_language              None            None\n",
      "source_language                      None            None\n",
      "target_language                      None            None\n",
      "scope                                None            None\n",
      "industrial                           None            None\n",
      "bidirectional                        None            None\n",
      "NominalVariables.domain\n",
      "                         fisher-exact-test  chi2-exact-test\n",
      "venue                                  NaN              NaN\n",
      "search_type                            NaN              NaN\n",
      "transformation_language           1.000000         0.493624\n",
      "source_language                   1.000000         0.512172\n",
      "target_language                   0.296852         0.231078\n",
      "scope                             1.000000         0.674707\n",
      "industrial                        0.652674         0.326915\n",
      "bidirectional                     0.423788         0.349938\n",
      "NominalVariables.transformation_language\n",
      "                 fisher-exact-test  chi2-exact-test\n",
      "venue                          NaN              NaN\n",
      "search_type                    NaN              NaN\n",
      "domain                    1.000000         0.493624\n",
      "source_language           0.561719         0.358641\n",
      "target_language           0.725637         0.592254\n",
      "scope                     0.913043         0.538480\n",
      "industrial                0.768116         0.308022\n",
      "bidirectional             1.000000         0.687225\n",
      "NominalVariables.source_language\n",
      "                         fisher-exact-test  chi2-exact-test\n",
      "venue                                  NaN              NaN\n",
      "search_type                            NaN              NaN\n",
      "domain                            1.000000         0.512172\n",
      "transformation_language           0.555722         0.358641\n",
      "target_language                   1.000000         0.469454\n",
      "scope                             0.777111         0.423190\n",
      "industrial                        1.000000         0.831456\n",
      "bidirectional                     1.000000         0.551913\n",
      "NominalVariables.target_language\n",
      "                         fisher-exact-test  chi2-exact-test\n",
      "venue                                  NaN              NaN\n",
      "search_type                            NaN              NaN\n",
      "domain                            0.299350         0.231078\n",
      "transformation_language           0.724638         0.592254\n",
      "source_language                   1.000000         0.469454\n",
      "scope                             1.000000         0.615060\n",
      "industrial                        1.000000         0.349938\n",
      "bidirectional                     0.043478         0.030197\n",
      "NominalVariables.scope\n",
      "                         fisher-exact-test  chi2-exact-test\n",
      "venue                                  NaN              NaN\n",
      "search_type                            NaN              NaN\n",
      "domain                            1.000000         0.674707\n",
      "transformation_language           0.892054         0.538480\n",
      "source_language                   0.757621         0.423190\n",
      "target_language                   1.000000         0.615060\n",
      "industrial                        0.702149         0.449329\n",
      "bidirectional                     0.424788         0.263597\n",
      "NominalVariables.industrial\n",
      "                         fisher-exact-test  chi2-exact-test\n",
      "venue                                  NaN              NaN\n",
      "search_type                            NaN              NaN\n",
      "domain                            0.674663         0.326915\n",
      "transformation_language           0.750125         0.308022\n",
      "source_language                   1.000000         0.831456\n",
      "target_language                   1.000000         0.349938\n",
      "scope                             0.721639         0.449329\n",
      "bidirectional                     1.000000         1.000000\n",
      "NominalVariables.bidirectional\n",
      "                         fisher-exact-test  chi2-exact-test\n",
      "venue                                  NaN              NaN\n",
      "search_type                            NaN              NaN\n",
      "domain                            0.423288         0.349938\n",
      "transformation_language           1.000000         0.687225\n",
      "source_language                   1.000000         0.551913\n",
      "target_language                   0.038481         0.030197\n",
      "scope                             0.440280         0.263597\n",
      "industrial                        1.000000         1.000000\n"
     ]
    }
   ],
   "source": [
    "def generate_comp_fisher_exact_test(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    # Check for the condition where there's only one row and both variables are NaN\n",
    "    if len(subset_data) == 1 and pd.isna(subset_data[field_name]).all() and pd.isna(subset_data[dependency_field_name]).all():\n",
    "        return\n",
    "\n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(subset_data[field_name], subset_data[dependency_field_name],\n",
    "                                     values=subset_data['Frequency'], aggfunc='sum', dropna=False).fillna(0)\n",
    "\n",
    "    # Perform Fisher's Exact Test\n",
    "    fisher_result = fisher_exact(contingency_table, simulate_pval=True)\n",
    "\n",
    "    # return fisher_result\n",
    "    return fisher_result\n",
    "\n",
    "\n",
    "def chi2_test(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    variable = get_variable(field_name, NominalVariables)\n",
    "    dependency_variable = get_variable(dependency_field_name, NominalVariables)\n",
    "\n",
    "    subset_data = beautify_data_comp(field_name, dependency_field_name,\n",
    "                                      variable, dependency_variable, data)\n",
    "\n",
    "    if subset_data.empty: return\n",
    "\n",
    "    # Check for the condition where both variables are NaN\n",
    "    if len(subset_data) == 1 and pd.isna(subset_data[field_name]).all() and pd.isna(subset_data[dependency_field_name]).all():\n",
    "        return\n",
    "\n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(subset_data[field_name], subset_data[dependency_field_name],\n",
    "                                     values=subset_data['Frequency'], aggfunc='sum', dropna=False).fillna(0)\n",
    "   \n",
    "    # Calculating the Chi-squared statistic\n",
    "    chi2_result = chi2_contingency(contingency_table)\n",
    "\n",
    "    return chi2_result.pvalue # type: ignore\n",
    "\n",
    "fisher_exact_test_vector = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, generate_comp_fisher_exact_test)\n",
    "                       for field_name in nominal.data.columns}\n",
    "\n",
    "chi2_exact_test_vector = {NominalVariables[field_name]: evaluate_comparative_dependency_field(field_name, nominal, chi2_test)\n",
    "                       for field_name in nominal.data.columns}\n",
    "\n",
    "\n",
    "for fixed_stat in NominalVariables:\n",
    "    print(fixed_stat)\n",
    "    df = pd.DataFrame({\n",
    "        'fisher-exact-test': [fisher_exact_test_vector[fixed_stat][stat]\n",
    "                            for stat in fisher_exact_test_vector[fixed_stat]],\n",
    "        'chi2-exact-test': [chi2_exact_test_vector[fixed_stat][stat]\n",
    "                            for stat in fisher_exact_test_vector[fixed_stat]]\n",
    "    }, index=[stat.name for stat in fisher_exact_test_vector[fixed_stat]])\n",
    "\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Shapiro Wilk's Correlation Test<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shapiro Wilk's Correlation Test\n",
    "\n",
    "def generate_comp_shapiro_wilk_test(field_name: str, continuous_df: pd.DataFrame):\n",
    "    subset_data = continuous_df[field_name].fillna(0)\n",
    "\n",
    "    shapiro_result = shapiro(subset_data)\n",
    "\n",
    "    return shapiro_result\n",
    "\n",
    "comp_shapiro_wilk_tests = {ContinuousVariables[field_name]: generate_comp_shapiro_wilk_test(field_name, continuous.data)\n",
    "                          for field_name in continuous.data.columns}\n",
    "print(comp_shapiro_wilk_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Pearson's Correlation Test<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comp_pearson_cor_test(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    _, pvalue = comp_shapiro_wilk_tests[ContinuousVariables[field_name]]\n",
    "    _, dpvalue = comp_shapiro_wilk_tests[ContinuousVariables[dependency_field_name]]\n",
    "\n",
    "    if not (pvalue > 0.05 and dpvalue > 0.05): return\n",
    "    \n",
    "    # Perform Pearson's correlation test\n",
    "    pearson_coefficient, p_value = pearsonr(data[field_name].fillna(0), data[dependency_field_name].fillna(0))\n",
    "\n",
    "    return pearson_coefficient, p_value\n",
    "\n",
    "comp_pearson_cor_tests = {ContinuousVariables[field_name]: evaluate_comparative_dependency_field(field_name, continuous, generate_comp_pearson_cor_test)\n",
    "                       for field_name in continuous.data.columns}\n",
    "\n",
    "print(comp_pearson_cor_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"color:#98c377\">Spearman's Correlation Test<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comp_spearman_cor_test(field_name: str, dependency_field_name: str, data: pd.DataFrame):\n",
    "    _, pvalue = comp_shapiro_wilk_tests[ContinuousVariables[field_name]]\n",
    "    _, dpvalue = comp_shapiro_wilk_tests[ContinuousVariables[dependency_field_name]]\n",
    "\n",
    "    if  pvalue > 0.05 and dpvalue > 0.05: return\n",
    "  \n",
    "    # Perform Spearman's correlation test\n",
    "    spearman_result = spearmanr(data[field_name].fillna(0), data[dependency_field_name].fillna(0))\n",
    "\n",
    "    return spearman_result\n",
    "\n",
    "comp_spearman_cor_tests = {ContinuousVariables[field_name]: evaluate_comparative_dependency_field(field_name, continuous, generate_comp_spearman_cor_test)\n",
    "                       for field_name in continuous.data.columns}\n",
    "\n",
    "print(comp_spearman_cor_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
